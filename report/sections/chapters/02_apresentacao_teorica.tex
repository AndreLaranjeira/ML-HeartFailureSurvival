\chapter{Apresentação teórica} \label{chap:apresentacao_teorica}

Neste capítulo, alguns conceitos teóricos são explanados com o intuito de fornecer ao leitor o embasamento teórico necessário para a compreensão completa deste trabalho.

\section{Aprendizado de máquina}

O campo de estudo de aprendizado de máquina é uma vasta área da computação, possuindo várias aplicações, objetos de estudo e focos de pesquisa interdisciplinares. Resumidamente, podemos dizer que essa área estuda como "construir programas de computador que melhoram seu desempenho em alguma tarefa por meio da experiência"\cite[p.29]{machine_learning}. Atualmente, utilizamos o aprendizado de máquina para várias aplicações como algoritmos de recomendações de conteúdo, programas de reconhecimento e classificação de imagens e a realização de análises de risco financeiro.

Para utilizarmos o aprendizado de máquina para resolvermos alguma problema, faz-se necessário definir matematicamente uma tarefa a ser realizada, uma ou mais métricas de desempenho atreladas à realização da tarefa e a fonte de experiência que será utilizada pelo modelo para aprender a realizar a tarefa\cite[p.29]{machine_learning}. Também precisamos escolher um ou mais tipos de modelo de aprendizado de máquina que serão utilizados para aprender a realizar a tarefa com base em um treinamento feito com a fonte de experiência avaliado sob a ótica das métricas de desempenho escolhidas.

\subsection{Especificação de uma tarefa}

Qualquer problema de aprendizado de máquina deve possuir uma tarefa a ser realizada, que representa o objetivo a ser atingido pelo uso de aprendizado de máquina. A especificação dessa tarefa sempre deve possuir o formato de uma função matemática para permitir que um programa de computador consiga aprendê-la. Assim, podemos afirmar que qualquer tarefa de aprendizado de máquina pode ser representada, genericamente, pela função $T : V \rightarrow R$, onde $V$ é um conjunto de variáveis disponibilizado para a realização da tarefa de aprendizado de máquina e $R$ é o resultado esperado da tarefa de aprendizado de máquina.

Para um programa de aprendizado de máquina realizar a tarefa proposta, este deve aprender a função $T$. Entretanto, na grande maioria dos problemas de aprendizado de máquina, a função $T$ não é conhecida e o problema proposto se resume a aproximar uma \textit{descrição operacional} de $T$\cite[p.8]{machine_learning}. Dessa forma, o programa de aprendizado de máquina deve então utilizar o processo de aprendizado com base na fonte de experiência para adquirir uma função $\hat{T}$ que seja uma boa aproximação da função $T$.

Neste trabalho, o problema de previsão de insuficiência cardíaca pode ser descrito como sendo um problema de \textit{classificação binária}, em que a tarefa proposta é representada pela função $P : V_{p} \rightarrow \{0, 1\}$, onde $V_{p}$ são as variáveis fornecidas que descrevem o paciente e o conjunto imagem $\{0, 1\}$ representa uma previsão se o paciente irá sofrer complicações devido à insuficiência cardíaca (1) ou não (0).

\subsection{Fonte de experiência}

Para permitir que um programa de aprendizado de máquina aprenda uma aproximação $\hat{T}$ da função $T$, é necessário a utilização de uma fonte de experiência que forneça, direta ou indiretamente, uma maneira do programa de treinamento inferir o comportamento da função $T$. Essa fonte de experiência pode ser obtida de várias formas, as quais variam consideravelmente dependendo da tarefa em questão e do método de aprendizado almejado para o programa computacional, de forma que o tipo de recurso utilizado como fonte de experiência não apenas é determinante no sucesso ou fracasso do aprendizado, como também define uma categoria de aprendizado que será adotada pelo programa computacional.

O tipo mais comum de fonte de experiência utilizada é um conjunto de dados com exemplos que possuem variáveis e o resultado da aplicação dessas variáveis à função $T$, categoria de aprendizado conhecida como aprendizado supervisionado. Alguns outros tipos de fontes de experiência e suas respectivas categorias de aprendizado incluem: o uso de um conjunto de dados com exemplos com variáveis mas sem nenhum resultado da função $T$, categoria conhecida como aprendizado não supervisionado; o uso de um conjunto de dados com exemplos com variáveis mas nem sempre com o resultado da aplicação dessas variáveis à função $T$, categoria conhecida como aprendizado semi-supervisionado; e uma exploração da função $T$ feita pelo próprio programa computacional com base em uma métrica de recompensa, categoria conhecida como aprendizado por reforço.

Para que a função de aproximação $\hat{T}$ aprendida pelo programa de aprendizado de máquina com base na fonte de experiência utilizada seja uma boa aproximação da função $T$, é necessário que a fonte de experiência utilizada seja uma boa aproximação dos exemplos que o programa de aprendizado de máquina encontrará ao longo de sua avaliação e uso, uma suposição que é apenas parcialmente verdadeira\cite[p.6]{machine_learning}. Isso pode levar a ocorrência de um fenômeno denominado sobreajuste (ou \textit{overfitting}) no processo de aprendizado do programa computacional. O sobreajuste ocorre quando o uso de uma fonte de experiência pequena ou com ruídos estatísticos resulta em uma aproximação $\hat{T}$ aprendida pelo programa computacional que se adequa melhor do que $T$ aos dados da fonte de experiência utilizada mas que não generaliza corretamente os dados englobados em todo o domínio da função $T$\cite[p.79-80]{machine_learning}.

Neste trabalho, o programa de previsão de insuficiência cardíaca utilizou como fonte de experiência para seu treinamento um conjunto de dados\cite{larxel_dataset} composto de exemplos com variáveis e o resultado da aplicação dessas variáveis à função $T$, tomando parte, assim, na categoria de problemas de aprendizado supervisionado. O capítulo \ref{chap:procedimento_adotado} aborda alguns cuidados utilizados para evitar a ocorrência de sobreajuste no processo de aprendizado.

\subsection{Modelos de aprendizado}

Com a definição da tarefa a ser realizada e da fonte de experiência, devemos escolher um ou mais modelos de aprendizado de máquina que serão treinados pelo programa computacional. Cada modelo de aprendizado de máquina possui uma forma específica para representar a função $\hat{T}$ e para aprender com a fonte de experiência disponibilizada. Dessa forma, antes de qualquer outra consideração, o modelo de treinamento escolhido deve ser compatível com a categoria de aprendizado estabelecida pela fonte de experiência escolhida. Cada modelo de aprendizado também possui um conjunto de hiper-parâmetros que são utilizados para a realização de ajustes finos na representação de $\hat{T}$ utilizada pelo modelo e no método de aprendizado empregado. Com a otimização desses hiper-parâmetros, o modelo de aprendizado pode aprender mais com a fonte de experiência e, consequentemente, melhorar a aproximação $\hat{T}$ obtida em relação à função $T$.

A escolha do modelo de aprendizado apresenta um \textit{trade-off} importante na representação escolhida para a função $\hat{T}$: quanto maior a representatividade do modelo, maior é o número de dados necessários para treiná-lo\cite[p.8]{machine_learning} e menor é a interpretabilidade do modelo\cite[p.25]{statistical_learning}. Essa é uma consideração importante a ser feita dependendo do tamanho da fonte de experiência utilizada e do próposito para o qual o aprendizado de máquina está sendo empregado.

Neste trabalho, o programa de previsão de insuficiência cardíaca avaliou dois tipos de modelos de aprendizado distintos para aprendizado de máquina: perceptron multicamada e floresta aleatória. Ambos estes modelos são utilizados para problemas de aprendizado da categoria de aprendizado supervisionado e possuem um grande conjunto de combinações possíveis de hiper-parâmetros.

\subsubsection{Perceptron multicamada}

O modelo de aprendizado de perceptron multicamada é um tipo de rede neural artificial, classe de modelos de aprendizado inspirada pelos sistemas de aprendizado biológicos compostos por redes de neurônios interconectados. As redes neurais são compostas por várias unidades computacionais agrupadas em camadas, cada unidade computacional recebendo um conjunto de entradas reais e fornecendo uma saída real, a qual pode ser utilizada como entrada de outra unidade computacional da rede neural\cite[p.82]{machine_learning}.

O perceptron é uma das unidades computacionais que podem ser utilizadas para compor uma rede neural artificial. Cada perceptron pode ser descrito por uma função $P(\vec{x} \cdot \vec{w})$, onde $\vec{x} = (1, x_{1}, x_{2}, ..., x_{n}) \in \Re^{n+1}$ é um vetor de entradas reais, e $\vec{w} = (w_{0}, w_{1}, ..., w_{n}) \in \Re^{n+1}$ é um vetor de pesos, onde cada valor $w_{i}$ representa o peso que o perceptron fornece à entrada $x_{i}$. Existem várias funções que podem ser utilizadas como a função $P$ que descreve o perceptron com alguns dos exemplos mais comuns sendo as funções degrau, as funções sigmoide, as funções de Unidade Linear Retificada (ReLU)\nomenclature{ReLU}{Unidade Linear Retificada} e a função identidade. Os valores de cada peso $w_{i}$ do perceptron variam ao longo do processo de aprendizagem com a fonte de experiência e geralmente possuem como valor inicial um número aleatório pertencente ao intervalo $(-1, 1)$.

Quando temos uma rede neural composta por várias camadas de perceptrons, temos o modelo de aprendizado conhecido como perceptron multicamada. Ao longo do processo de aprendizado supervisionado do perceptron multicamada, as entradas de cada exemplo do conjunto de dados são inseridas na rede e a saída fornecida pela rede é comparada com a saída registrada no conjunto de dados. Após a execução de certo número de exemplos, o perceptron multicamada executa um algoritmo de retropropagação para ajustar os pesos de seus perceptrons de forma a minimizar uma medida de erro, que geralmente é o erro quadrático entre as saídas geradas pela rede neural e as saídas registradas no conjunto de dados\cite[p.97]{machine_learning}. Cada treinamento realizado desta maneira sobre todo o conjunto de dados é conhecido como uma época e, após certo número de épocas de aprendizado, o modelo de perceptron multicamada obtém uma boa aproximação $\hat{T}$. Para a execução do algoritmo de retropropagação, é necessário que a função $P$ utilizada pelos perceptrons de cada camada seja uma função diferenciável, de forma que todas as funções de ativação utilizadas em um perceptron multicamada devem ser diferenciáveis.

No modelo de perceptron multicamada, alguns dos hiper-parâmetros que podemos modificar, além das dimensões da rede neural em termos de número de camadas e de número de perceptrons por camada, incluem a função diferenciável utilizada como função de ativação $P$ dos perceptrons de uma camada, a medida de erro minimizada na execução do algoritmo de retropropagação, o número de épocas de aprendizado, a aplicação de um fator de \textit{dropout} no aprendizado de uma camada e a utilização de um fator de regularização sobre os pesos dos perceptrons de uma camada. Destes, os fatores de \textit{dropout} e de regularização de pesos merecem maior explicação. Um fator $d \in [0, 1)$ de \textit{dropout} para uma camada de perceptrons faz com que, durante o treinamento, os perceptrons dessa camada sobrescrevam aleatoriamente uma fração $d$ de suas entradas com o valor 0, permitindo que todas as entradas sejam treinadas para influenciarem a ativação do perceptron. Já o fator de regularização de pesos estabelece, para cada perceptron de uma camada, uma penalidade na medida de erro que é proporcional à uma função dos pesos do perceptron, como soma ou soma quadrática, incentivando os pesos do perceptron a se manterem baixos para diminuir a complexidade da aproximação $\hat{T}$ aprendida\cite[p.111]{machine_learning}.

\subsubsection{Floresta aleatória}

O modelo de aprendizado do tipo floresta aleatória é um tipo de modelo agrupado sob a classificação de modelos de aprendizado baseados em árvores de decisão, os quais utilizam uma ou mais árvores de decisão para gerar uma aproximação $\hat{T}$ para a função $T$. Dessa forma, antes de podermos explicar o modelo de aprendizado do tipo floresta aleatória, devemos explicar o modelo de aprendizado do tipo árvore de decisão.

Uma árvore de decisão é um modelo de aprendizado que busca subdividir o domínio $V$ da função $T$ em um número de regiões menores $R_{1}, R_{2}, ..., R_{n}$ de forma que $R_{i} \cap R_{j} = \emptyset \text{ } \forall i \ne j$ e que essas regiões agrupem os exemplos fornecidos pelo conjunto de dados utilizado como fonte de experiência. A representação final da função $\hat{T}$ é um conjunto de regras de divisão de $V$ cuja representação gráfica se assemelha a uma árvore e cujo resultado fornecido para um arranjo de variáveis que se encontre dentro de uma região $R_{i} \subset V$ equivale à média ou à moda dos resultados de todos os exemplos do conjunto de dados utilizado como fonte de experiência cujas variáveis também se encontrem dentro da região $R_{i}$\cite[p.303]{statistical_learning}. Cada subdivisão feita em $V$ para gerar uma nova região $R_{i} \subset V$ busca sempre diminuir ao máximo, por meio de uma abordagem gulosa, a soma dos quadrados dos erros entre os resultados da aplicação de $\hat{T}$ e os resultados dos exemplos do conjunto de dados usado como fonte de experiência, no caso de um problema de regressão, ou uma medida de variância dos agrupamentos de classes dos exemplos do conjunto de dados da fonte de experiência, no caso de um problema de classificação\cite[p.306-307, 312]{statistical_learning}.

A utilização de uma única árvore de decisão para gerar uma aproximação $\hat{T}$ para a função $T$ não fornece bons resultados, mas a utilização de uma aproximação $\hat{T}$ gerada pelo consenso do resultado de várias árvores de decisão pode fornecer resultados com excelente acurácia\cite[p.303]{statistical_learning}. O modelo de aprendizado de floresta aleatória gera uma aproximação $\hat{T}$ com base no consenso de um número arbitrário de árvores de decisão, onde cada árvore de decisão é gerada utilizando um conjunto de dados obtido pela escolha aleatória com possibilidade de repetição dos exemplos do conjunto de dados que serve como fonte de experiência, de forma que ambos conjuntos de dados tenham o mesmo tamanho (técnica conhecida como \textit{bootstrapping}). Além disso, na construção de uma floresta aleatória, sempre que uma das árvores de decisão subdivide o dominío $V$, esta considera apenas um subconjunto, também aleatório, de variáveis do conjunto de dados utilizado como fonte de experiência. Estas duas características auxiliam na diminuição da variância dos resultados gerados pelo consenso das árvores de decisão, aumentando a acurácia dos resultados da aproximação $\hat{T}$ fornecida por uma floresta aleatória\cite[p.316-321]{statistical_learning}.

No modelo de floresta aleatória, alguns dos hiper-parâmetros que podemos modificar incluem: o número de árvores de decisão utilizado; a medida de variância ou de erro a ser minimizada na realização das subdivisões do domínio $V$; o tamanho do subconjunto de variáveis, pertencentes ao conjunto de dados utilizado como fonte de experiência, consideradas na realização de cada subdivisão do domínio $V$; e vários hiper-parâmetros utilizados para limitar o crescimento de cada árvore de decisão como número mínimo de exemplos para compor uma folha, número mínimo de exemplos para realizar uma nova subdivisão do domínio $V$, profundidade máxima das árvores de decisão e número máximo de folhas das árvores de decisão. A utilização de hiper-parâmetros que limitam o crescimento das árvores de decisão resulta em uma aproximação $\hat{T}$ com menor complexidade, o que diminui a probabilidade de ocorrência de sobreajuste\cite[p.307]{statistical_learning}.

\subsection{Métricas de desempenho}

Por fim, devemos escolher uma ou mais métricas de desempenho para mensurar objetivamente o desempenho do programa de aprendizado de máquina no aprendizado da tarefa $T$ proposta. Cada categoria de aprendizado possui suas próprias métricas de desempenho e a natureza do problema proposto também influencia as métricas utilizadas. Por exemplo, para a categoria de aprendizado supervisionado, as métricas de desempenho utilizadas diferem em casos de problemas de regressão e de classificação. A escolha das métricas de desempenho é importante para que a avaliação dos modelos de aprendizado treinados ilustre adequadamente o desempenho do modelo em aprender a tarefa $T$ em conformidade com o objetivo a ser atingido pelo uso do aprendizado de máquina.

Neste trabalho, em que o problema estudado é categorizado como um problema de aprendizado supervisionado de classificação, a métrica de desempenho adotada foi a média da acurácia das classificações feitas por um modelo de treinamento para os exemplos contidos em um número de subconjuntos de dados utilizados para fins de validação ou de teste e, portanto, não utilizados no processo de aprendizado do modelo. Outras métricas que podem ser utilizadas para problemas dessa categoria incluem a precisão das classificações realizadas, a sensibilidade (\textit{recall}) das classificações realizadas e o Coeficiente de Correlação de Matthews (MCC)\nomenclature{MCC}{Coeficiente de Correlação de Matthews}.

Para definirmos matematicamente cada uma dessas métricas de problemas de aprendizado supervisionado de classificação, vamos estabelecer que $N$ é o número total de previsões feitas por um modelo, $T_{p}$ é o número de previsões que foram verdadeiros positivos, $T_{n}$ é o número de previsões que foram verdadeiros negativos, $F_{p}$ é o número de previsões que foram falsos positivos, e $F_{n}$ é o número de previsões que foram falsos negativos. Dessa forma, temos que $N = T_{p} + F_{p} + T_{n} + F_{n}$. Com essa definições, podemos definir a acurácia ($Acc$) pela equação \ref{eq:accuracy}, a precisão ($Precision$) pela equação \ref{eq:precision}, a sensibilidade ($Recall$) pela equação \ref{eq:recall}, e o Coeficiente de Correlação de Matthews ($MCC$) pela equação \ref{eq:mcc}.

\begin{equation} \label{eq:accuracy}
  Acc = \frac{T_{p} + T_{n}}{N}
\end{equation}

\begin{equation} \label{eq:precision}
  Precision = \frac{T_{p}}{T_{p} + F_{p}}
\end{equation}

\begin{equation} \label{eq:recall}
  Recall = \frac{T_{p}}{T_{p} + F_{n}}
\end{equation}

\begin{equation} \label{eq:mcc}
  MCC = \frac{(T_{p} \times T_{n}) - (F_{p} \times F_{n})}{ \\
    \sqrt{ \\
      (T_{p} + F_{p}) \times (T_{p} + F_{n}) \times (T_{n} + F_{p}) \\
      \times (T_{n} + F_{n}) \\
    } \\
  }
\end{equation}

\section{Funcionamento de um website}

O funcionamento de um website é um processo complexo que envolve vários aspectos relacionados ao servidor que hospeda o website, ao protocolo utilizado pelo navegador de internet do cliente para localizar esse servidor na internet, e ao processo de comunicação entre o servidor que hospeda o website e o navegador de internet para permitir que o cliente utilize o website. Para este trabalho, nosso foco estará apenas na estrutura do website em si, e não nos protocolos utilizados por um navegador de internet para localizar o website na internet ou em detalhes mais complexos da comunicação entre o navegador de internet do cliente e o servidor que hospeda o website. De forma bem resumida, podemos dividir a estrutura padrão de um website em dois componentes básicos, os quais não precisam ser implementados no mesmo programa ou mesmo armazenados no mesmo servidor: o \textit{backend} e o \textit{frontend}.

O \textit{backend} de um website engloba o banco de dados utilizado para o armazenamento dos dados do website e as funções ou métodos utilizados para acessar, criar, editar, apagar ou de alguma forma gerenciar esses dados. Dessa forma, o \textit{backend} geralmente é visualizado apenas pelos programadores envolvidos na construção do website e não pelos usuários e é utilizado para fornecer os dados que são visualizados e acessados pelos usuários no uso do website.

O \textit{frontend} de um website é composto pelas telas do website que são renderizadas pelo browser e por funções ou métodos utilizados para requisitar dados ao \textit{backend} do website e determinar quais telas ou elementos de telas que devem ser renderizados conforme as ações do usuário. Dessa forma, os usuários de um website geralmente interagem apenas com o \textit{frontend} do website ao utilizar um navegador de internet.

Geralmente, o \textit{backend} e o \textit{frontend} de um website são construídos no mesmo programa para serem executados de maneira acoplada no mesmo servidor e poderem se comunicar por meio de chamadas locais de funções. Entretanto, um novo padrão de projeto de websites tem se estabelecido, no qual o \textit{backend} do website é construído em um programa separado do \textit{frontend} para poder ser acessado diretamente por meio de requisições do Protocolo de Transferência de Hipertexto (HTTP)\nomenclature{HTTP}{Protocolo de Transferência de Hipertexto} ou até mesmo por mais de um \textit{frontend} simultaneamente. Quando isso ocorre, dizemos que o \textit{backend} do website se trata de uma Interface de Programação de Aplicações (\textit{API})\nomenclature{API}{Interface de Programação de Aplicações}.

A utilização de uma \textit{API} como \textit{backend} do website faz com que tenhamos que executar o \textit{backend} do website e o \textit{frontend} do website em servidores diferentes ou em portas diferentes do mesmo servidor, de forma que a comunicação entre \textit{backend} e \textit{frontend} do website passa a ser feita por requisições HTTP e não pela execução de funções locais. Embora essa arquitetura gere mais trabalho na programação da lógica do website, ela abre um número maior de possibilidades para o programador ao permitir que diversos \textit{frontends} no formato de interfaces web, aplicativos ou clientes de protocolo HTTP utilizem, simultaneamente, a API de \textit{backend} criada. Além disso, essa arquitetura facilita a realização de testes com o website ao permitir que a separação dos testes de \textit{backend} e de \textit{frontend} seja feita com mais facilidade.

No próximo capítulo, detalharemos o procedimento adotado ao longo deste trabalho.
